{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# assit data generation"
      ],
      "metadata": {
        "id": "EfX6SHkYQw6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#  file路径\n\n",
        "test_path = '/content/Assistment_challenge_test.csv'\n",
        "train_path = '/content/Assistment_challenge_train.csv'\n",
        "merged_output_path = '/content/Assistment_challenge_merged.csv'\n",
        "train_output_path = '/content/Assistment_challenge_train_new.csv'\n",
        "test_output_path = '/content/Assistment_challenge_test_new.csv'\n",
        "\n",
        "#  1. 读取data集\n\n",
        "try:\n",
        "    df_test = pd.read_csv(test_path)\n",
        "    df_train = pd.read_csv(train_path)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: File not found - {e}\")\n",
        "    exit()\n",
        "\n",
        "#  2. 检查列名一致性\n\n",
        "print(\"Test dataset columns:\", df_test.columns.tolist())\n",
        "print(\"Train dataset columns:\", df_train.columns.tolist())\n",
        "\n",
        "if list(df_test.columns) != list(df_train.columns):\n",
        "    print(\"Warning: Column names are not identical. Aligning to common columns.\")\n",
        "    common_columns = df_test.columns.intersection(df_train.columns).tolist()\n",
        "    print(\"Common columns:\", common_columns)\n",
        "    df_test = df_test[common_columns]\n",
        "    df_train = df_train[common_columns]\n",
        "else:\n",
        "    print(\"Column names are identical. Proceeding with merge.\")\n",
        "\n",
        "#  3. 检查data量\n\n",
        "print(f\"\\nTest dataset rows: {len(df_test)}\")\n",
        "print(f\"Train dataset rows: {len(df_train)}\")\n",
        "\n",
        "#  4. 检查 studentId 和 skill 列是否存在\n\n",
        "id_column = 'studentId'\n",
        "skill_column = 'skill'\n",
        "if id_column not in df_test.columns or id_column not in df_train.columns:\n",
        "    print(f\"Error: Column '{id_column}' not found in one or both datasets.\")\n",
        "    exit()\n",
        "if skill_column not in df_test.columns or skill_column not in df_train.columns:\n",
        "    print(f\"Error: Column '{skill_column}' not found in one or both datasets.\")\n",
        "    exit()\n",
        "\n",
        "#  5. 检查train集和test集的 studentId 是否有重叠\n\n",
        "test_students = set(df_test[id_column].unique())\n",
        "train_students = set(df_train[id_column].unique())\n",
        "intersection = test_students.intersection(train_students)\n",
        "if len(intersection) > 0:\n",
        "    print(f\"\\nWarning: Found {len(intersection)} overlapping studentIds between test and train datasets.\")\n",
        "    print(\"Merging may result in duplicate records. Proceeding with merge.\")\n",
        "else:\n",
        "    print(f\"\\nNo overlapping studentIds found in original datasets.\")\n",
        "\n",
        "#  6. mergedata集\n\n",
        "merged_df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "print(f\"\\nMerged dataset rows: {len(merged_df)}\")\n",
        "print(f\"Merged dataset unique studentIds: {merged_df['studentId'].nunique()}\")\n",
        "print(f\"Merged dataset unique skills: {merged_df['skill'].nunique()}\")\n",
        "print(\"Merged dataset columns:\", merged_df.columns.tolist())\n",
        "\n",
        "#  7. 检查merge后是否有重复行\n\n",
        "duplicates = merged_df.duplicated().sum()\n",
        "if duplicates > 0:\n",
        "    print(f\"\\nWarning: Found {duplicates} duplicate rows in the merged dataset.\")\n",
        "    #  可选择去重\n\n",
        "    #  merged_df = merged_df.drop_duplicates()\n\n",
        "    #  print(f\"After removing duplicates, merged dataset rows: {len(merged_df)}\")\n\n",
        "else:\n",
        "    print(\"\\nNo duplicate rows found in the merged dataset.\")\n",
        "\n",
        "#  8. process缺失值\n\n",
        "merged_df = merged_df.dropna(subset=[id_column, skill_column])\n",
        "print(f\"\\nAfter removing rows with missing studentId or skill, rows: {len(merged_df)}\")\n",
        "\n",
        "#  9. savemerge后的data集\n\n",
        "merged_df.to_csv(merged_output_path, index=False)\n",
        "print(f\"\\nMerged dataset saved to: {merged_output_path}\")\n",
        "\n",
        "#  10. 按 studentId 进行 2:8 划分，确保train集覆盖所有技能\n\n",
        "unique_students = merged_df['studentId'].unique()\n",
        "all_skills = set(merged_df['skill'].unique())\n",
        "train_students = []\n",
        "test_students = []\n",
        "\n",
        "#  按技能分组，找到每个技能对应的student\n\n",
        "student_skills = merged_df.groupby('studentId')['skill'].unique().apply(set)\n",
        "rare_skills = set()\n",
        "for skill in all_skills:\n",
        "    students_with_skill = student_skills[student_skills.apply(lambda x: skill in x)].index\n",
        "    if len(students_with_skill) <= 5:  #  假设技能出现在少于 5 个student为稀有技能\n\n",
        "        rare_skills.add(skill)\n",
        "        train_students.extend(students_with_skill)\n",
        "\n",
        "#  去重并转换为集合\n\n",
        "train_students = list(set(train_students))\n",
        "remaining_students = [s for s in unique_students if s not in train_students]\n",
        "\n",
        "#  对剩余student进行 2:8 划分\n\n",
        "train_size = int(0.8 * len(unique_students)) - len(train_students)\n",
        "if train_size > 0 and remaining_students:\n",
        "    train_remaining, test_remaining = train_test_split(\n",
        "        remaining_students,\n",
        "        train_size=train_size,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_students.extend(train_remaining)\n",
        "    test_students = test_remaining\n",
        "else:\n",
        "    test_students = remaining_students\n",
        "\n",
        "#  11. 确保train集覆盖所有技能\n\n",
        "train_df = merged_df[merged_df['studentId'].isin(train_students)]\n",
        "train_skills = set(train_df['skill'].unique())\n",
        "if train_skills != all_skills:\n",
        "    print(\"\\nWarning: Training set does not cover all skills. Adjusting...\")\n",
        "    missing_skills = all_skills - train_skills\n",
        "    for skill in missing_skills:\n",
        "        students_with_skill = merged_df[merged_df['skill'] == skill]['studentId'].unique()\n",
        "        if students_with_skill.size > 0:\n",
        "            train_students.append(students_with_skill[0])\n",
        "            test_students = [s for s in test_students if s not in students_with_skill]\n",
        "    train_df = merged_df[merged_df['studentId'].isin(train_students)]\n",
        "    train_skills = set(train_df['skill'].unique())\n",
        "\n",
        "#  12. 生成test集\n\n",
        "test_df = merged_df[merged_df['studentId'].isin(test_students)]\n",
        "\n",
        "#  13. 验证 studentId 无重叠\n\n",
        "train_students_set = set(train_students)\n",
        "test_students_set = set(test_students)\n",
        "intersection = train_students_set.intersection(test_students_set)\n",
        "if len(intersection) > 0:\n",
        "    print(f\"Error: Found {len(intersection)} overlapping studentIds in new split.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"\\nNo overlapping studentIds between new train and test datasets.\")\n",
        "\n",
        "#  14. 验证技能覆盖\n\n",
        "test_skills = set(test_df['skill'].unique())\n",
        "if not test_skills.issubset(train_skills):\n",
        "    print(\"\\nError: Test set contains skills not in training set.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"\\nAll skills in test set are present in training set.\")\n",
        "\n",
        "#  15. 检查划分后的data量和比例\n\n",
        "total_students = len(unique_students)\n",
        "train_student_count = len(train_students)\n",
        "test_student_count = len(test_students)\n",
        "train_student_percentage = (train_student_count / total_students) * 100\n",
        "test_student_percentage = (test_student_count / total_students) * 100\n",
        "\n",
        "print(f\"\\nNew train dataset: {len(train_df)} rows, {train_student_count} studentIds ({train_student_percentage:.2f}%)\")\n",
        "print(f\"New test dataset: {len(test_df)} rows, {test_student_count} studentIds ({test_student_percentage:.2f}%)\")\n",
        "print(f\"Training set unique skills: {len(train_skills)}\")\n",
        "print(f\"Test set unique skills: {len(test_skills)}\")\n",
        "\n",
        "#  16. 验证行数比例\n\n",
        "total_rows = len(merged_df)\n",
        "train_row_percentage = (len(train_df) / total_rows) * 100\n",
        "test_row_percentage = (len(test_df) / total_rows) * 100\n",
        "print(f\"New train dataset row proportion: {train_row_percentage:.2f}%\")\n",
        "print(f\"New test dataset row proportion: {test_row_percentage:.2f}%\")\n",
        "\n",
        "if abs(test_row_percentage - 20) < 5 and abs(train_row_percentage - 80) < 5:\n",
        "    print(\"The new split is approximately 2:8 (test:train) by rows.\")\n",
        "else:\n",
        "    print(f\"The new split does not closely match 2:8 by rows. Actual split: {test_row_percentage:.2f}:{train_row_percentage:.2f}\")\n",
        "\n",
        "#  17. 检查列一致性\n\n",
        "if list(train_df.columns) == list(test_df.columns):\n",
        "    print(\"\\nNew train and test datasets have identical columns.\")\n",
        "else:\n",
        "    print(\"\\nError: New train and test datasets have different columns.\")\n",
        "    exit()\n",
        "\n",
        "#  18. save划分后的data集\n\n",
        "train_df.to_csv(train_output_path, index=False)\n",
        "test_df.to_csv(test_output_path, index=False)\n",
        "print(f\"\\nNew train dataset saved to: {train_output_path}\")\n",
        "print(f\"New test dataset saved to: {test_output_path}\")\n",
        "\n",
        "#  19. 最终验证\n\n",
        "print(\"\\nFinal verification:\")\n",
        "print(f\"New train dataset rows: {len(train_df)}, unique studentIds: {train_df['studentId'].nunique()}, unique skills: {train_df['skill'].nunique()}\")\n",
        "print(f\"New test dataset rows: {len(test_df)}, unique studentIds: {test_df['studentId'].nunique()}, unique skills: {test_df['skill'].nunique()}\")\n",
        "print(f\"No duplicate studentIds confirmed: {len(train_df[train_df['studentId'].isin(test_students)]) == 0}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-sNnjLQQ02n",
        "outputId": "6219db69-a406-4e89-fc3d-f34d881ff31c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset columns: ['studentId', 'MiddleSchoolId', 'InferredGender', 'SY ASSISTments Usage', 'AveKnow', 'AveCarelessness', 'AveCorrect', 'NumActions', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'action_num', 'skill', 'problemId', 'problemType', 'assignmentId', 'assistmentId', 'startTime', 'endTime', 'timeTaken', 'correct', 'original', 'hint', 'hintCount', 'hintTotal', 'scaffold', 'bottomHint', 'attemptCount', 'frIsHelpRequest', 'frPast5HelpRequest', 'frPast8HelpRequest', 'stlHintUsed', 'past8BottomOut', 'totalFrPercentPastWrong', 'totalFrPastWrongCount', 'frPast5WrongCount', 'frPast8WrongCount', 'totalFrTimeOnSkill', 'timeSinceSkill', 'frWorkingInSchool', 'totalFrAttempted', 'totalFrSkillOpportunities', 'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frTimeTakenOnScaffolding', 'frTotalSkillOpportunitiesScaffolding', 'totalFrSkillOpportunitiesByScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'sumRight', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'consecutiveErrorsInRow', 'sumTime3SDWhen3RowRight', 'sumTimePerSkill', 'totalTimeByPercentCorrectForskill', 'Prev5count', 'timeOver80', 'manywrong', 'confidence(BORED)', 'confidence(CONCENTRATING)', 'confidence(CONFUSED)', 'confidence(FRUSTRATED)', 'confidence(OFF TASK)', 'confidence(GAMING)', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING', 'Ln-1', 'Ln', 'MCAS', 'Enrolled', 'Selective', 'isSTEM', 'knowledge']\n",
            "Train dataset columns: ['studentId', 'MiddleSchoolId', 'InferredGender', 'SY ASSISTments Usage', 'AveKnow', 'AveCarelessness', 'AveCorrect', 'NumActions', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'action_num', 'skill', 'problemId', 'problemType', 'assignmentId', 'assistmentId', 'startTime', 'endTime', 'timeTaken', 'correct', 'original', 'hint', 'hintCount', 'hintTotal', 'scaffold', 'bottomHint', 'attemptCount', 'frIsHelpRequest', 'frPast5HelpRequest', 'frPast8HelpRequest', 'stlHintUsed', 'past8BottomOut', 'totalFrPercentPastWrong', 'totalFrPastWrongCount', 'frPast5WrongCount', 'frPast8WrongCount', 'totalFrTimeOnSkill', 'timeSinceSkill', 'frWorkingInSchool', 'totalFrAttempted', 'totalFrSkillOpportunities', 'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frTimeTakenOnScaffolding', 'frTotalSkillOpportunitiesScaffolding', 'totalFrSkillOpportunitiesByScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'sumRight', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'consecutiveErrorsInRow', 'sumTime3SDWhen3RowRight', 'sumTimePerSkill', 'totalTimeByPercentCorrectForskill', 'Prev5count', 'timeOver80', 'manywrong', 'confidence(BORED)', 'confidence(CONCENTRATING)', 'confidence(CONFUSED)', 'confidence(FRUSTRATED)', 'confidence(OFF TASK)', 'confidence(GAMING)', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING', 'Ln-1', 'Ln', 'MCAS', 'Enrolled', 'Selective', 'isSTEM', 'knowledge']\n",
            "Column names are identical. Proceeding with merge.\n",
            "\n",
            "Test dataset rows: 85687\n",
            "Train dataset rows: 89457\n",
            "\n",
            "Warning: Found 1496 overlapping studentIds between test and train datasets.\n",
            "Merging may result in duplicate records. Proceeding with merge.\n",
            "\n",
            "Merged dataset rows: 175144\n",
            "Merged dataset unique studentIds: 1690\n",
            "Merged dataset unique skills: 26\n",
            "Merged dataset columns: ['studentId', 'MiddleSchoolId', 'InferredGender', 'SY ASSISTments Usage', 'AveKnow', 'AveCarelessness', 'AveCorrect', 'NumActions', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'action_num', 'skill', 'problemId', 'problemType', 'assignmentId', 'assistmentId', 'startTime', 'endTime', 'timeTaken', 'correct', 'original', 'hint', 'hintCount', 'hintTotal', 'scaffold', 'bottomHint', 'attemptCount', 'frIsHelpRequest', 'frPast5HelpRequest', 'frPast8HelpRequest', 'stlHintUsed', 'past8BottomOut', 'totalFrPercentPastWrong', 'totalFrPastWrongCount', 'frPast5WrongCount', 'frPast8WrongCount', 'totalFrTimeOnSkill', 'timeSinceSkill', 'frWorkingInSchool', 'totalFrAttempted', 'totalFrSkillOpportunities', 'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frTimeTakenOnScaffolding', 'frTotalSkillOpportunitiesScaffolding', 'totalFrSkillOpportunitiesByScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'sumRight', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'consecutiveErrorsInRow', 'sumTime3SDWhen3RowRight', 'sumTimePerSkill', 'totalTimeByPercentCorrectForskill', 'Prev5count', 'timeOver80', 'manywrong', 'confidence(BORED)', 'confidence(CONCENTRATING)', 'confidence(CONFUSED)', 'confidence(FRUSTRATED)', 'confidence(OFF TASK)', 'confidence(GAMING)', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING', 'Ln-1', 'Ln', 'MCAS', 'Enrolled', 'Selective', 'isSTEM', 'knowledge']\n",
            "\n",
            "No duplicate rows found in the merged dataset.\n",
            "\n",
            "After removing rows with missing studentId or skill, rows: 175144\n",
            "\n",
            "Merged dataset saved to: /content/Assistment_challenge_merged.csv\n",
            "\n",
            "No overlapping studentIds between new train and test datasets.\n",
            "\n",
            "All skills in test set are present in training set.\n",
            "\n",
            "New train dataset: 140090 rows, 1352 studentIds (80.00%)\n",
            "New test dataset: 35054 rows, 338 studentIds (20.00%)\n",
            "Training set unique skills: 26\n",
            "Test set unique skills: 26\n",
            "New train dataset row proportion: 79.99%\n",
            "New test dataset row proportion: 20.01%\n",
            "The new split is approximately 2:8 (test:train) by rows.\n",
            "\n",
            "New train and test datasets have identical columns.\n",
            "\n",
            "New train dataset saved to: /content/Assistment_challenge_train_new.csv\n",
            "New test dataset saved to: /content/Assistment_challenge_test_new.csv\n",
            "\n",
            "Final verification:\n",
            "New train dataset rows: 140090, unique studentIds: 1352, unique skills: 26\n",
            "New test dataset rows: 35054, unique studentIds: 338, unique skills: 26\n",
            "No duplicate studentIds confirmed: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hampton data generation"
      ],
      "metadata": {
        "id": "6s96rySCRYsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#  file路径\n\n",
        "test_path = '/content/HamptonAlg_test.csv'\n",
        "train_path = '/content/HamptonAlg_train.csv'\n",
        "merged_output_path = '/content/HamptonAlg_merged.csv'\n",
        "train_output_path = '/content/HamptonAlg_train_new.csv'\n",
        "test_output_path = '/content/HamptonAlg_test_new.csv'\n",
        "\n",
        "#  1. 读取data集\n\n",
        "try:\n",
        "    df_test = pd.read_csv(test_path)\n",
        "    df_train = pd.read_csv(train_path)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: File not found - {e}\")\n",
        "    exit()\n",
        "\n",
        "#  2. 检查列名一致性\n\n",
        "print(\"Test dataset columns:\", df_test.columns.tolist())\n",
        "print(\"Train dataset columns:\", df_train.columns.tolist())\n",
        "\n",
        "if list(df_test.columns) != list(df_train.columns):\n",
        "    print(\"Warning: Column names are not identical. Aligning to common columns.\")\n",
        "    common_columns = df_test.columns.intersection(df_train.columns).tolist()\n",
        "    print(\"Common columns:\", common_columns)\n",
        "    df_test = df_test[common_columns]\n",
        "    df_train = df_train[common_columns]\n",
        "else:\n",
        "    print(\"Column names are identical. Proceeding with merge.\")\n",
        "\n",
        "#  3. 检查data量\n\n",
        "print(f\"\\nTest dataset rows: {len(df_test)}\")\n",
        "print(f\"Train dataset rows: {len(df_train)}\")\n",
        "\n",
        "#  4. 检查 student 和 knowledge 列是否存在\n\n",
        "id_column = 'student'\n",
        "skill_column = 'knowledge'\n",
        "if id_column not in df_test.columns or id_column not in df_train.columns:\n",
        "    print(f\"Error: Column '{id_column}' not found in one or both datasets.\")\n",
        "    exit()\n",
        "if skill_column not in df_test.columns or skill_column not in df_train.columns:\n",
        "    print(f\"Error: Column '{skill_column}' not found in one or both datasets.\")\n",
        "    exit()\n",
        "\n",
        "#  5. 检查train集和test集的 student 是否有重叠\n\n",
        "test_students = set(df_test[id_column].unique())\n",
        "train_students = set(df_train[id_column].unique())\n",
        "intersection = test_students.intersection(train_students)\n",
        "if len(intersection) > 0:\n",
        "    print(f\"\\nWarning: Found {len(intersection)} overlapping students between test and train datasets.\")\n",
        "    print(\"Merging may result in duplicate records. Proceeding with merge.\")\n",
        "else:\n",
        "    print(f\"\\nNo overlapping students found in original datasets.\")\n",
        "\n",
        "#  6. mergedata集\n\n",
        "merged_df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "print(f\"\\nMerged dataset rows: {len(merged_df)}\")\n",
        "print(f\"Merged dataset unique students: {merged_df['student'].nunique()}\")\n",
        "print(f\"Merged dataset unique knowledge: {merged_df['knowledge'].nunique()}\")\n",
        "print(\"Merged dataset columns:\", merged_df.columns.tolist())\n",
        "\n",
        "#  7. 检查merge后是否有重复行\n\n",
        "duplicates = merged_df.duplicated().sum()\n",
        "if duplicates > 0:\n",
        "    print(f\"\\nWarning: Found {duplicates} duplicate rows in the merged dataset.\")\n",
        "    #  可选择去重\n\n",
        "    #  merged_df = merged_df.drop_duplicates()\n\n",
        "    #  print(f\"After removing duplicates, merged dataset rows: {len(merged_df)}\")\n\n",
        "else:\n",
        "    print(\"\\nNo duplicate rows found in the merged dataset.\")\n",
        "\n",
        "#  8. process缺失值\n\n",
        "merged_df = merged_df.dropna(subset=[id_column, skill_column])\n",
        "print(f\"\\nAfter removing rows with missing student or knowledge, rows: {len(merged_df)}\")\n",
        "\n",
        "#  9. savemerge后的data集\n\n",
        "merged_df.to_csv(merged_output_path, index=False)\n",
        "print(f\"\\nMerged dataset saved to: {merged_output_path}\")\n",
        "\n",
        "#  10. 按 student 进行 2:8 划分，确保train集覆盖所有 knowledge\n\n",
        "unique_students = merged_df['student'].unique()\n",
        "all_knowledge = set(merged_df['knowledge'].unique())\n",
        "train_students = []\n",
        "test_students = []\n",
        "\n",
        "#  按 knowledge 分组，找到每个 knowledge 对应的student\n\n",
        "student_knowledge = merged_df.groupby('student')['knowledge'].unique().apply(set)\n",
        "rare_knowledge = set()\n",
        "for knowledge in all_knowledge:\n",
        "    students_with_knowledge = student_knowledge[student_knowledge.apply(lambda x: knowledge in x)].index\n",
        "    if len(students_with_knowledge) <= 5:  #  假设 knowledge 出现在少于 5 个student为稀有\n\n",
        "        rare_knowledge.add(knowledge)\n",
        "        train_students.extend(students_with_knowledge)\n",
        "\n",
        "#  去重并转换为集合\n\n",
        "train_students = list(set(train_students))\n",
        "remaining_students = [s for s in unique_students if s not in train_students]\n",
        "\n",
        "#  对剩余student进行 2:8 划分\n\n",
        "train_size = int(0.8 * len(unique_students)) - len(train_students)\n",
        "if train_size > 0 and remaining_students:\n",
        "    train_remaining, test_remaining = train_test_split(\n",
        "        remaining_students,\n",
        "        train_size=train_size,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_students.extend(train_remaining)\n",
        "    test_students = test_remaining\n",
        "else:\n",
        "    test_students = remaining_students\n",
        "\n",
        "#  11. 确保train集覆盖所有 knowledge\n\n",
        "train_df = merged_df[merged_df['student'].isin(train_students)]\n",
        "train_knowledge = set(train_df['knowledge'].unique())\n",
        "if train_knowledge != all_knowledge:\n",
        "    print(\"\\nWarning: Training set does not cover all knowledge. Adjusting...\")\n",
        "    missing_knowledge = all_knowledge - train_knowledge\n",
        "    for knowledge in missing_knowledge:\n",
        "        students_with_knowledge = merged_df[merged_df['knowledge'] == knowledge]['student'].unique()\n",
        "        if students_with_knowledge.size > 0:\n",
        "            train_students.append(students_with_knowledge[0])\n",
        "            test_students = [s for s in test_students if s not in students_with_knowledge]\n",
        "    train_df = merged_df[merged_df['student'].isin(train_students)]\n",
        "    train_knowledge = set(train_df['knowledge'].unique())\n",
        "\n",
        "#  12. 生成test集\n\n",
        "test_df = merged_df[merged_df['student'].isin(test_students)]\n",
        "\n",
        "#  13. 验证 student 无重叠\n\n",
        "train_students_set = set(train_students)\n",
        "test_students_set = set(test_students)\n",
        "intersection = train_students_set.intersection(test_students_set)\n",
        "if len(intersection) > 0:\n",
        "    print(f\"Error: Found {len(intersection)} overlapping students in new split.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"\\nNo overlapping students between new train and test datasets.\")\n",
        "\n",
        "#  14. 验证 knowledge 覆盖\n\n",
        "test_knowledge = set(test_df['knowledge'].unique())\n",
        "if not test_knowledge.issubset(train_knowledge):\n",
        "    print(\"\\nError: Test set contains knowledge not in training set.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"\\nAll knowledge in test set are present in training set.\")\n",
        "\n",
        "#  15. 检查划分后的data量和比例\n\n",
        "total_students = len(unique_students)\n",
        "train_student_count = len(train_students)\n",
        "test_student_count = len(test_students)\n",
        "train_student_percentage = (train_student_count / total_students) * 100\n",
        "test_student_percentage = (test_student_count / total_students) * 100\n",
        "\n",
        "print(f\"\\nNew train dataset: {len(train_df)} rows, {train_student_count} students ({train_student_percentage:.2f}%)\")\n",
        "print(f\"New test dataset: {len(test_df)} rows, {test_student_count} students ({test_student_percentage:.2f}%)\")\n",
        "print(f\"Training set unique knowledge: {len(train_knowledge)}\")\n",
        "print(f\"Test set unique knowledge: {len(test_knowledge)}\")\n",
        "\n",
        "#  16. 验证行数比例\n\n",
        "total_rows = len(merged_df)\n",
        "train_row_percentage = (len(train_df) / total_rows) * 100\n",
        "test_row_percentage = (len(test_df) / total_rows) * 100\n",
        "print(f\"New train dataset row proportion: {train_row_percentage:.2f}%\")\n",
        "print(f\"New test dataset row proportion: {test_row_percentage:.2f}%\")\n",
        "\n",
        "if abs(test_row_percentage - 20) < 5 and abs(train_row_percentage - 80) < 5:\n",
        "    print(\"The new split is approximately 2:8 (test:train) by rows.\")\n",
        "else:\n",
        "    print(f\"The new split does not closely match 2:8 by rows. Actual split: {test_row_percentage:.2f}:{train_row_percentage:.2f}\")\n",
        "\n",
        "#  17. 检查列一致性\n\n",
        "if list(train_df.columns) == list(test_df.columns):\n",
        "    print(\"\\nNew train and test datasets have identical columns.\")\n",
        "else:\n",
        "    print(\"\\nError: New train and test datasets have different columns.\")\n",
        "    exit()\n",
        "\n",
        "#  18. save划分后的data集\n\n",
        "train_df.to_csv(train_output_path, index=False)\n",
        "test_df.to_csv(test_output_path, index=False)\n",
        "print(f\"\\nNew train dataset saved to: {train_output_path}\")\n",
        "print(f\"New test dataset saved to: {test_output_path}\")\n",
        "\n",
        "#  19. 最终验证\n\n",
        "print(\"\\nFinal verification:\")\n",
        "print(f\"New train dataset rows: {len(train_df)}, unique students: {train_df['student'].nunique()}, unique knowledge: {train_df['knowledge'].nunique()}\")\n",
        "print(f\"New test dataset rows: {len(test_df)}, unique students: {test_df['student'].nunique()}, unique knowledge: {test_df['knowledge'].nunique()}\")\n",
        "print(f\"No duplicate students confirmed: {len(train_df[train_df['student'].isin(test_students)]) == 0}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ7HxzDCRb6S",
        "outputId": "d4705cdb-9ae3-4511-b675-e89cd388b795"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset columns: ['actionid', 'lesson', 'student', 'assessment', 'cell.context', 'UNKNOWN', 'action', 'answer', 'message', 'message.type', 'production', 'X.1', 'time', 'numstep', 'helpintermedtime', 'knowledge']\n",
            "Train dataset columns: ['actionid', 'lesson', 'student', 'assessment', 'cell.context', 'UNKNOWN', 'action', 'answer', 'message', 'message.type', 'production', 'X.1', 'time', 'numstep', 'helpintermedtime', 'knowledge']\n",
            "Column names are identical. Proceeding with merge.\n",
            "\n",
            "Test dataset rows: 41167\n",
            "Train dataset rows: 199070\n",
            "\n",
            "Warning: Found 57 overlapping students between test and train datasets.\n",
            "Merging may result in duplicate records. Proceeding with merge.\n",
            "\n",
            "Merged dataset rows: 240237\n",
            "Merged dataset unique students: 59\n",
            "Merged dataset unique knowledge: 87\n",
            "Merged dataset columns: ['actionid', 'lesson', 'student', 'assessment', 'cell.context', 'UNKNOWN', 'action', 'answer', 'message', 'message.type', 'production', 'X.1', 'time', 'numstep', 'helpintermedtime', 'knowledge']\n",
            "\n",
            "No duplicate rows found in the merged dataset.\n",
            "\n",
            "After removing rows with missing student or knowledge, rows: 240237\n",
            "\n",
            "Merged dataset saved to: /content/HamptonAlg_merged.csv\n",
            "\n",
            "No overlapping students between new train and test datasets.\n",
            "\n",
            "All knowledge in test set are present in training set.\n",
            "\n",
            "New train dataset: 195948 rows, 47 students (79.66%)\n",
            "New test dataset: 44289 rows, 12 students (20.34%)\n",
            "Training set unique knowledge: 87\n",
            "Test set unique knowledge: 86\n",
            "New train dataset row proportion: 81.56%\n",
            "New test dataset row proportion: 18.44%\n",
            "The new split is approximately 2:8 (test:train) by rows.\n",
            "\n",
            "New train and test datasets have identical columns.\n",
            "\n",
            "New train dataset saved to: /content/HamptonAlg_train_new.csv\n",
            "New test dataset saved to: /content/HamptonAlg_test_new.csv\n",
            "\n",
            "Final verification:\n",
            "New train dataset rows: 195948, unique students: 47, unique knowledge: 87\n",
            "New test dataset rows: 44289, unique students: 12, unique knowledge: 86\n",
            "No duplicate students confirmed: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hint abuse"
      ],
      "metadata": {
        "id": "4utnc_5bMUbh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mS1z-XnHwJ2i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba5e11ac-3d77-4297-ab39-31655500da54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable Names in Assistment_challenge_train.csv:\n",
            "['studentId', 'MiddleSchoolId', 'InferredGender', 'SY ASSISTments Usage', 'AveKnow', 'AveCarelessness', 'AveCorrect', 'NumActions', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'action_num', 'skill', 'problemId', 'problemType', 'assignmentId', 'assistmentId', 'startTime', 'endTime', 'timeTaken', 'correct', 'original', 'hint', 'hintCount', 'hintTotal', 'scaffold', 'bottomHint', 'attemptCount', 'frIsHelpRequest', 'frPast5HelpRequest', 'frPast8HelpRequest', 'stlHintUsed', 'past8BottomOut', 'totalFrPercentPastWrong', 'totalFrPastWrongCount', 'frPast5WrongCount', 'frPast8WrongCount', 'totalFrTimeOnSkill', 'timeSinceSkill', 'frWorkingInSchool', 'totalFrAttempted', 'totalFrSkillOpportunities', 'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frTimeTakenOnScaffolding', 'frTotalSkillOpportunitiesScaffolding', 'totalFrSkillOpportunitiesByScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'sumRight', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'consecutiveErrorsInRow', 'sumTime3SDWhen3RowRight', 'sumTimePerSkill', 'totalTimeByPercentCorrectForskill', 'Prev5count', 'timeOver80', 'manywrong', 'confidence(BORED)', 'confidence(CONCENTRATING)', 'confidence(CONFUSED)', 'confidence(FRUSTRATED)', 'confidence(OFF TASK)', 'confidence(GAMING)', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING', 'Ln-1', 'Ln', 'MCAS', 'Enrolled', 'Selective', 'isSTEM', 'knowledge']\n",
            "\n",
            "Unique values in 'correct': [0 1]\n",
            "Sample values in 'timeTaken': [49.0, 3.999999762, 83.00000048, 5.0, 12.00000024]\n",
            "Unique values in 'hint': [1 0]\n",
            "Unique values in 'frIsHelpRequest': [1 0]\n",
            "Number of records: 140090\n",
            "Number of unique students: 1352\n",
            "Number of unique problems: 1452\n",
            "\n",
            "Simulating Hint Abuse Attack with 5% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 7004\n",
            "Number of unique students: 1352, selected: 83\n",
            "Number of unique problems: 1452, selected: 83\n",
            "Number of candidate poison indices: 399\n",
            "Number of final poison indices: 399\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "HintCount distribution after 5% poisoning:\n",
            "hintCount\n",
            "0    65203\n",
            "1    28843\n",
            "2    18148\n",
            "3    16923\n",
            "4     6325\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 5% poisoning:\n",
            "gaming_label\n",
            "0    139691\n",
            "1      1979\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/Assistment_hint_abuse_5.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_268dd239-6c8f-4050-999b-5ed1d543ce46\", \"Assistment_hint_abuse_5.csv\", 81648768)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating Hint Abuse Attack with 25% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 35022\n",
            "Number of unique students: 1352, selected: 187\n",
            "Number of unique problems: 1452, selected: 187\n",
            "Number of candidate poison indices: 2467\n",
            "Number of final poison indices: 2467\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "HintCount distribution after 25% poisoning:\n",
            "hintCount\n",
            "0    64174\n",
            "1    32647\n",
            "2    19346\n",
            "3    17952\n",
            "4     7831\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 25% poisoning:\n",
            "gaming_label\n",
            "0    137623\n",
            "1     12355\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/Assistment_hint_abuse_25.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6e6e75f1-abfd-4f52-a520-4247bae7baf8\", \"Assistment_hint_abuse_25.csv\", 86566724)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating Hint Abuse Attack with 50% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 70045\n",
            "Number of unique students: 1352, selected: 264\n",
            "Number of unique problems: 1452, selected: 264\n",
            "Number of candidate poison indices: 4558\n",
            "Number of final poison indices: 4558\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "HintCount distribution after 50% poisoning:\n",
            "hintCount\n",
            "0    63224\n",
            "1    35961\n",
            "2    20854\n",
            "3    18928\n",
            "4     9343\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 50% poisoning:\n",
            "gaming_label\n",
            "0    135532\n",
            "1     22757\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/Assistment_hint_abuse_50.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85f424cc-c79b-4b88-99f9-ba5363f144bc\", \"Assistment_hint_abuse_50.csv\", 91353805)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "#  Define global data directory for unified path management\n\n",
        "DATA_DIR = '/content/poisoned_datasets/'\n",
        "\n",
        "#  Function to load dataset\n\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load CSV file and return a DataFrame.\"\"\"\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    return df\n",
        "\n",
        "#  Function to simulate Hint Abuse Attack\n\n",
        "def simulate_hint_abuse(df, poison_ratio):\n",
        "    \"\"\"Simulate Hint Abuse Attack on the dataset.\"\"\"\n",
        "    #  Create a deep copy to ensure data independence\n\n",
        "    df_poisoned = df.copy()\n",
        "\n",
        "    #  Initialize gaming_label column with explicit integer type\n\n",
        "    df_poisoned['gaming_label'] = 0\n",
        "    df_poisoned['gaming_label'] = df_poisoned['gaming_label'].astype('Int64')  #  Nullable integer type\n\n",
        "\n",
        "    #  Assert key columns exist\n\n",
        "    assert 'studentId' in df_poisoned.columns, \"Column 'studentId' not found\"\n",
        "    assert 'problemId' in df_poisoned.columns, \"Column 'problemId' not found\"\n",
        "    assert 'correct' in df_poisoned.columns, \"Column 'correct' not found\"\n",
        "    assert 'timeTaken' in df_poisoned.columns, \"Column 'timeTaken' not found\"\n",
        "    assert 'hint' in df_poisoned.columns, \"Column 'hint' not found\"\n",
        "    assert 'hintCount' in df_poisoned.columns, \"Column 'hintCount' not found\"\n",
        "    assert 'hintTotal' in df_poisoned.columns, \"Column 'hintTotal' not found\"\n",
        "    assert 'frIsHelpRequest' in df_poisoned.columns, \"Column 'frIsHelpRequest' not found\"\n",
        "    assert 'gaming_label' in df_poisoned.columns, \"Column 'gaming_label' not initialized\"\n",
        "\n",
        "    #  Debug: Check initial unique values in gaming_label\n\n",
        "    print(f\"Initial unique values in 'gaming_label': {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Randomly select students and problems\n\n",
        "    n_poison = int(len(df) * poison_ratio)  #  Total number of records to poison\n\n",
        "    unique_students = df['studentId'].unique()\n",
        "    unique_problems = df['problemId'].unique()\n",
        "    n_select = min(int(np.sqrt(n_poison)), len(unique_students), len(unique_problems))  #  Balance selection\n\n",
        "\n",
        "    #  Debug: Check selection counts\n\n",
        "    print(f\"Number of records to poison: {n_poison}\")\n",
        "    print(f\"Number of unique students: {len(unique_students)}, selected: {n_select}\")\n",
        "    print(f\"Number of unique problems: {len(unique_problems)}, selected: {n_select}\")\n",
        "\n",
        "    #  Handle case where no records can be poisoned\n\n",
        "    if n_select == 0 or n_poison == 0:\n",
        "        print(\"Warning: No records selected for poisoning due to small dataset or low poison ratio.\")\n",
        "        return df_poisoned\n",
        "\n",
        "    selected_students = np.random.choice(unique_students, size=n_select, replace=False)\n",
        "    selected_problems = np.random.choice(unique_problems, size=n_select, replace=False)\n",
        "\n",
        "    #  Identify records to poison\n\n",
        "    mask = (df['studentId'].isin(selected_students)) & (df['problemId'].isin(selected_problems))\n",
        "    poison_indices = df.index[mask].tolist()\n",
        "\n",
        "    #  Debug: Check poison indices\n\n",
        "    print(f\"Number of candidate poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    poison_indices = np.random.choice(poison_indices, size=min(n_poison, len(poison_indices)), replace=False)\n",
        "\n",
        "    #  Debug: Check final poison indices\n\n",
        "    print(f\"Number of final poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    #  Generate new rows for hint requests\n\n",
        "    new_rows = []\n",
        "    columns = df_poisoned.columns.tolist()  #  Ensure all columns are included\n\n",
        "    if len(poison_indices) > 0:\n",
        "        for idx in poison_indices:\n",
        "            base_row = df_poisoned.loc[idx].copy()\n",
        "            #  Generate 3-5 hint requests\n\n",
        "            hint_count = np.random.randint(3, 6)  #  3-5 hints\n\n",
        "            interval = np.random.uniform(0.5, 1.0, hint_count)  #  0.5-1 second intervals\n\n",
        "            for i in range(hint_count):\n",
        "                new_row = base_row.copy()\n",
        "                new_row['hint'] = 1\n",
        "                new_row['hintCount'] = base_row['hintCount'] + 1 if pd.notna(base_row['hintCount']) else 1\n",
        "                new_row['hintTotal'] = base_row['hintTotal'] + 1 if pd.notna(base_row['hintTotal']) else 1\n",
        "                new_row['frIsHelpRequest'] = 1\n",
        "                new_row['timeTaken'] = interval[i]\n",
        "                new_row['correct'] = 0  #  No answer yet\n\n",
        "                new_row['gaming_label'] = 1\n",
        "                #  Ensure new_row is a DataFrame with correct columns\n\n",
        "                new_row_df = pd.Series(new_row, index=columns).to_frame().T\n",
        "                new_rows.append(new_row_df)\n",
        "            #  Update original row (submit correct answer or no answer)\n\n",
        "            df_poisoned.loc[idx, 'hintCount'] = base_row['hintCount'] + hint_count if pd.notna(base_row['hintCount']) else hint_count\n",
        "            df_poisoned.loc[idx, 'hintTotal'] = base_row['hintTotal'] + hint_count if pd.notna(base_row['hintTotal']) else hint_count\n",
        "            df_poisoned.loc[idx, 'timeTaken'] = 0.5\n",
        "            df_poisoned.loc[idx, 'gaming_label'] = 1\n",
        "            #  50% chance to submit no answer\n\n",
        "            if np.random.random() < 0.5:\n",
        "                df_poisoned.loc[idx, 'correct'] = np.nan\n",
        "                df_poisoned.loc[idx, 'frIsHelpRequest'] = 1  #  Still a help request\n\n",
        "            else:\n",
        "                df_poisoned.loc[idx, 'correct'] = 1\n",
        "                df_poisoned.loc[idx, 'frIsHelpRequest'] = 0  #  Correct answer, not a help request\n\n",
        "\n",
        "        #  Convert new_rows to DataFrame\n\n",
        "        if new_rows:\n",
        "            new_rows_df = pd.concat(new_rows, ignore_index=True)\n",
        "            #  Ensure data types match\n\n",
        "            for col in df_poisoned.columns:\n",
        "                if col in new_rows_df.columns:\n",
        "                    new_rows_df[col] = new_rows_df[col].astype(df_poisoned[col].dtype)\n",
        "            df_poisoned = pd.concat([df_poisoned, new_rows_df], ignore_index=True)\n",
        "\n",
        "    #  Debug: Check unique values in gaming_label after poisoning\n\n",
        "    print(f\"Unique values in 'gaming_label' after poisoning: {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Verify changes with assertions\n\n",
        "    assert df_poisoned['gaming_label'].isin([0, 1]).all(), f\"Invalid gaming_label values: {df_poisoned['gaming_label'].unique()}\"\n",
        "    print(f\"\\nHintCount distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['hintCount'].value_counts().head())\n",
        "    print(f\"Gaming_label distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['gaming_label'].value_counts().head())\n",
        "\n",
        "    return df_poisoned\n",
        "\n",
        "#  Main execution\n\n",
        "def main():\n",
        "    \"\"\"Main function to load data and simulate attacks.\"\"\"\n",
        "    #  Create directory for poisoned datasets\n\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "    #  Load dataset\n\n",
        "    assistment_file = '/content/Assistment_challenge_train_new.csv'\n",
        "    df = load_data(assistment_file)\n",
        "\n",
        "    #  Ensure relevant columns are numeric\n\n",
        "    for col in ['correct', 'timeTaken', 'hint', 'hintCount', 'hintTotal', 'frIsHelpRequest']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    #  Print dataset information\n\n",
        "    print(\"Variable Names in Assistment_challenge_train.csv:\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\nUnique values in 'correct':\", df['correct'].unique())\n",
        "    print(\"Sample values in 'timeTaken':\", df['timeTaken'].head().tolist())\n",
        "    print(\"Unique values in 'hint':\", df['hint'].unique())\n",
        "    print(\"Unique values in 'frIsHelpRequest':\", df['frIsHelpRequest'].unique())\n",
        "    print(\"Number of records:\", len(df))\n",
        "    print(\"Number of unique students:\", len(df['studentId'].unique()))\n",
        "    print(\"Number of unique problems:\", len(df['problemId'].unique()))\n",
        "\n",
        "    #  Simulate Hint Abuse Attack for each poison ratio\n\n",
        "    poison_ratios = [0.05, 0.25, 0.50]\n",
        "    for ratio in poison_ratios:\n",
        "        print(f\"\\nSimulating Hint Abuse Attack with {int(ratio*100)}% Poisoning...\")\n",
        "        #  Create a fresh copy for each iteration\n\n",
        "        df_copy = df.copy()\n",
        "        poisoned_df = simulate_hint_abuse(df_copy, ratio)\n",
        "\n",
        "        #  Save poisoned dataset\n\n",
        "        output_file = f'{DATA_DIR}Assistment_hint_abuse_{int(ratio*100)}.csv'\n",
        "        poisoned_df.to_csv(output_file, index=False, chunksize=10000)\n",
        "        print(f\"Saved poisoned dataset: {output_file}\")\n",
        "        files.download(output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# randon error"
      ],
      "metadata": {
        "id": "Z4WaLbltMZfl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cXa4WU2tMcau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#  Define global data directory for unified path management\n\n",
        "DATA_DIR = '/content/poisoned_datasets/'\n",
        "\n",
        "#  Function to load dataset\n\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load CSV file and return a DataFrame.\"\"\"\n",
        "    df = pd.read_csv(file_path, low_memory=False, dtype={'knowledge': float})\n",
        "    print(\"Initial knowledge distribution:\\n\", df['knowledge'].describe())\n",
        "    print(\"Unique values in knowledge:\", df['knowledge'].unique())\n",
        "    return df\n",
        "\n",
        "#  Function to simulate DPA\n\n",
        "def simulate_dpa(df, poison_ratio):\n",
        "    \"\"\"Simulate Data Poisoning Attack (DPA) on the dataset.\"\"\"\n",
        "    #  Deep copy\n\n",
        "    df_poisoned = df.copy()\n",
        "    #  Initialize gaming_label\n\n",
        "    if 'gaming_label' not in df_poisoned.columns:\n",
        "        df_poisoned['gaming_label'] = 0\n",
        "    df_poisoned['gaming_label'] = df_poisoned['gaming_label'].fillna(0).astype('Int64')\n",
        "    #  Ensure required columns exist\n\n",
        "    for col in ['correct', 'timeTaken', 'responseIsChosen', 'responseIsFillIn']:\n",
        "        assert col in df_poisoned.columns, f\"Column '{col}' not found\"\n",
        "    #  Number of rows to poison\n\n",
        "    n_poison = int(len(df) * poison_ratio)\n",
        "    if n_poison == 0:\n",
        "        print(\"No rows selected for poisoning due to low poison ratio.\")\n",
        "        return df_poisoned\n",
        "    poison_indices = np.random.choice(df.index, size=n_poison, replace=False)\n",
        "    #  Flip correctness for original 0/1\n\n",
        "    df_poisoned.loc[poison_indices, 'correct'] = df_poisoned.loc[poison_indices, 'correct'].fillna(0)\n",
        "    df_poisoned.loc[poison_indices, 'correct'] = 1 - df_poisoned.loc[poison_indices, 'correct']\n",
        "    #  Set timeTaken to 1\n\n",
        "    df_poisoned.loc[poison_indices, 'timeTaken'] = df_poisoned.loc[poison_indices, 'timeTaken'].fillna(1).astype(float)\n",
        "    #  For fill-in responses, assign random 0/1 instead of 0~99\n\n",
        "    fill_in_mask = df_poisoned.loc[poison_indices, 'responseIsFillIn'] == 1\n",
        "    fill_in_indices = poison_indices[fill_in_mask]\n",
        "    if len(fill_in_indices) > 0:\n",
        "        df_poisoned.loc[fill_in_indices, 'correct'] = np.random.randint(0, 2, size=len(fill_in_indices))\n",
        "    #  Mark poisoned rows\n\n",
        "    df_poisoned.loc[poison_indices, 'gaming_label'] = 1\n",
        "    #  Ensure all correct are 0/1 integers\n\n",
        "    df_poisoned['correct'] = df_poisoned['correct'].fillna(0).astype(int)\n",
        "    #  Protect knowledge column\n\n",
        "    if 'knowledge' in df_poisoned.columns:\n",
        "        df_poisoned['knowledge'] = df_poisoned['knowledge'].astype(float)\n",
        "    #  Debug info\n\n",
        "    print(\"Knowledge distribution after poisoning:\\n\", df_poisoned['knowledge'].describe())\n",
        "    print(\"Unique values in knowledge after poisoning:\", df_poisoned['knowledge'].unique())\n",
        "    print(f\"Unique values in 'correct' after poisoning: {df_poisoned['correct'].unique()}\")\n",
        "    print(f\"Unique values in 'gaming_label': {df_poisoned['gaming_label'].unique()}\")\n",
        "    print(f\"Correct distribution:\\n{df_poisoned['correct'].value_counts()}\")\n",
        "    print(f\"Gaming_label distribution:\\n{df_poisoned['gaming_label'].value_counts()}\")\n",
        "    return df_poisoned\n",
        "\n",
        "#  Main execution\n\n",
        "def main():\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "    assistment_file = '/content/Assistment_challenge_train_new.csv'\n",
        "    df = load_data(assistment_file)\n",
        "    #  Ensure numeric\n\n",
        "    for col in ['correct', 'timeTaken', 'responseIsChosen', 'responseIsFillIn']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    if 'knowledge' in df.columns:\n",
        "        df['knowledge'] = pd.to_numeric(df['knowledge'], errors='coerce').astype(float)\n",
        "    #  Simulate DPA\n\n",
        "    poison_ratios = [0.05, 0.25, 0.50]\n",
        "    for ratio in poison_ratios:\n",
        "        print(f\"\\nSimulating {int(ratio*100)}% poisoning...\")\n",
        "        df_copy = df.copy()\n",
        "        poisoned_df = simulate_dpa(df_copy, ratio)\n",
        "        output_file = f'{DATA_DIR}Assistment_poisoned_{int(ratio*100)}.csv'\n",
        "        poisoned_df.to_csv(output_file, index=False, float_format='%.2f')\n",
        "        print(f\"Saved: {output_file}\")\n",
        "        #  files.download(output_file)  # Uncomment to download in Colab\n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmQYP3A5AwLT",
        "outputId": "db6fee21-40b7-4de1-9107-c87df851726f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial knowledge distribution:\n",
            " count    140088.000000\n",
            "mean          8.286142\n",
            "std           8.564302\n",
            "min           0.000000\n",
            "25%           2.000000\n",
            "50%           5.000000\n",
            "75%          12.000000\n",
            "max          33.000000\n",
            "Name: knowledge, dtype: float64\n",
            "Unique values in knowledge: [ 0.  1.  2.  3.  4.  5.  6. nan  7.  8.  9. 10. 11. 12. 13. 14. 21. 24.\n",
            " 25. 26. 27. 28. 29. 30. 31. 32. 33.]\n",
            "\n",
            "Simulating 5% poisoning...\n",
            "Knowledge distribution after poisoning:\n",
            " count    140088.000000\n",
            "mean          8.286142\n",
            "std           8.564302\n",
            "min           0.000000\n",
            "25%           2.000000\n",
            "50%           5.000000\n",
            "75%          12.000000\n",
            "max          33.000000\n",
            "Name: knowledge, dtype: float64\n",
            "Unique values in knowledge after poisoning: [ 0.  1.  2.  3.  4.  5.  6. nan  7.  8.  9. 10. 11. 12. 13. 14. 21. 24.\n",
            " 25. 26. 27. 28. 29. 30. 31. 32. 33.]\n",
            "Unique values in 'correct' after poisoning: [0 1]\n",
            "Unique values in 'gaming_label': <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "Correct distribution:\n",
            "correct\n",
            "0    88504\n",
            "1    51586\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution:\n",
            "gaming_label\n",
            "0    133086\n",
            "1      7004\n",
            "Name: count, dtype: Int64\n",
            "Saved: /content/poisoned_datasets/Assistment_poisoned_5.csv\n",
            "\n",
            "Simulating 25% poisoning...\n",
            "Knowledge distribution after poisoning:\n",
            " count    140088.000000\n",
            "mean          8.286142\n",
            "std           8.564302\n",
            "min           0.000000\n",
            "25%           2.000000\n",
            "50%           5.000000\n",
            "75%          12.000000\n",
            "max          33.000000\n",
            "Name: knowledge, dtype: float64\n",
            "Unique values in knowledge after poisoning: [ 0.  1.  2.  3.  4.  5.  6. nan  7.  8.  9. 10. 11. 12. 13. 14. 21. 24.\n",
            " 25. 26. 27. 28. 29. 30. 31. 32. 33.]\n",
            "Unique values in 'correct' after poisoning: [1 0]\n",
            "Unique values in 'gaming_label': <IntegerArray>\n",
            "[1, 0]\n",
            "Length: 2, dtype: Int64\n",
            "Correct distribution:\n",
            "correct\n",
            "0    80205\n",
            "1    59885\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution:\n",
            "gaming_label\n",
            "0    105068\n",
            "1     35022\n",
            "Name: count, dtype: Int64\n",
            "Saved: /content/poisoned_datasets/Assistment_poisoned_25.csv\n",
            "\n",
            "Simulating 50% poisoning...\n",
            "Knowledge distribution after poisoning:\n",
            " count    140088.000000\n",
            "mean          8.286142\n",
            "std           8.564302\n",
            "min           0.000000\n",
            "25%           2.000000\n",
            "50%           5.000000\n",
            "75%          12.000000\n",
            "max          33.000000\n",
            "Name: knowledge, dtype: float64\n",
            "Unique values in knowledge after poisoning: [ 0.  1.  2.  3.  4.  5.  6. nan  7.  8.  9. 10. 11. 12. 13. 14. 21. 24.\n",
            " 25. 26. 27. 28. 29. 30. 31. 32. 33.]\n",
            "Unique values in 'correct' after poisoning: [1 0]\n",
            "Unique values in 'gaming_label': <IntegerArray>\n",
            "[1, 0]\n",
            "Length: 2, dtype: Int64\n",
            "Correct distribution:\n",
            "correct\n",
            "0    70283\n",
            "1    69807\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution:\n",
            "gaming_label\n",
            "1    70045\n",
            "0    70045\n",
            "Name: count, dtype: Int64\n",
            "Saved: /content/poisoned_datasets/Assistment_poisoned_50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "#  Define global data directory for unified path management\n\n",
        "DATA_DIR = '/content/poisoned_datasets/'\n",
        "\n",
        "#  Function to load dataset\n\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load CSV file and return a DataFrame.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "#  Function to simulate DPA\n\n",
        "def simulate_dpa(df, poison_ratio, correct_col='knowledge', time_col='time'):\n",
        "    \"\"\"Simulate Data Poisoning Attack (DPA) on the dataset.\"\"\"\n",
        "    #  Create a deep copy to ensure data independence\n\n",
        "    df_poisoned = df.copy()\n",
        "\n",
        "    #  Initialize gaming_label column with explicit integer type\n\n",
        "    if 'gaming_label' not in df_poisoned.columns:\n",
        "        df_poisoned['gaming_label'] = 0\n",
        "        df_poisoned['gaming_label'] = df_poisoned['gaming_label'].astype('Int64')  #  Nullable integer type\n\n",
        "    else:\n",
        "        df_poisoned['gaming_label'] = df_poisoned['gaming_label'].fillna(0).astype('Int64')  #  Preserve existing, fill NaN with 0\n\n",
        "\n",
        "    #  Assert key columns exist\n\n",
        "    assert correct_col in df_poisoned.columns, f\"Column '{correct_col}' not found\"\n",
        "    assert time_col in df_poisoned.columns, f\"Column '{time_col}' not found\"\n",
        "    assert 'gaming_label' in df_poisoned.columns, \"Column 'gaming_label' not initialized\"\n",
        "\n",
        "    #  Debug: Check initial unique values in gaming_label\n\n",
        "    print(f\"Initial unique values in 'gaming_label': {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Randomly select records to poison\n\n",
        "    n_poison = int(len(df) * poison_ratio)\n",
        "\n",
        "    #  Debug: Check number of records to poison\n\n",
        "    print(f\"Number of records to poison: {n_poison}\")\n",
        "\n",
        "    #  Handle case where no records can be poisoned\n\n",
        "    if n_poison == 0:\n",
        "        print(\"Warning: No records selected for poisoning due to low poison ratio.\")\n",
        "        return df_poisoned\n",
        "\n",
        "    poison_indices = np.random.choice(df.index, size=n_poison, replace=False)\n",
        "\n",
        "    #  Debug: Check final poison indices\n\n",
        "    print(f\"Number of final poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    #  Flip knowledge (using 86 - knowledge as complement)\n\n",
        "    df_poisoned.loc[poison_indices, correct_col] = 86 - df_poisoned.loc[poison_indices, correct_col]\n",
        "\n",
        "    #  Set time to 1 second\n\n",
        "    df_poisoned.loc[poison_indices, time_col] = 1\n",
        "\n",
        "    #  Mark poisoned rows with gaming_label = 1\n\n",
        "    df_poisoned.loc[poison_indices, 'gaming_label'] = 1\n",
        "\n",
        "    #  Debug: Check unique values in gaming_label after poisoning\n\n",
        "    print(f\"Unique values in 'gaming_label' after poisoning: {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Verify changes with assertions\n\n",
        "    assert df_poisoned['gaming_label'].isin([0, 1]).all(), f\"Invalid gaming_label values: {df_poisoned['gaming_label'].unique()}\"\n",
        "    print(f\"\\n{correct_col} distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned[correct_col].value_counts().head())\n",
        "    print(f\"Gaming_label distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['gaming_label'].value_counts())\n",
        "\n",
        "    return df_poisoned\n",
        "\n",
        "#  Main execution\n\n",
        "def main():\n",
        "    \"\"\"Main function to load data and simulate attacks.\"\"\"\n",
        "    #  Create directory for poisoned datasets\n\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "    #  Load dataset\n\n",
        "    hampton_file = '/content/HamptonAlg_train_new.csv'\n",
        "    df = load_data(hampton_file)\n",
        "\n",
        "    #  Ensure relevant columns are numeric\n\n",
        "    df['knowledge'] = pd.to_numeric(df['knowledge'], errors='coerce')\n",
        "    df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
        "\n",
        "    #  Print dataset information\n\n",
        "    print(\"Variable Names in HamptonAlg_train.csv:\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\nCheck if gaming_label exists:\", 'gaming_label' in df.columns)\n",
        "    print(\"\\nUnique values in 'knowledge':\", df['knowledge'].unique())\n",
        "    print(\"Sample values in 'time':\", df['time'].head().tolist())\n",
        "    print(\"Number of records:\", len(df))\n",
        "    print(\"Number of unique students:\", len(df['student'].unique()) if 'student' in df.columns else \"No 'student' column\")\n",
        "    print(\"Number of unique actions:\", len(df['actionid'].unique()) if 'actionid' in df.columns else \"No 'actionid' column\")\n",
        "\n",
        "    #  Simulate DPA for each poison ratio\n\n",
        "    poison_ratios = [0.05, 0.25, 0.50]\n",
        "    for ratio in poison_ratios:\n",
        "        print(f\"\\nSimulating DPA with {int(ratio*100)}% Poisoning...\")\n",
        "        #  Create a fresh copy for each iteration\n\n",
        "        df_copy = df.copy()\n",
        "        poisoned_df = simulate_dpa(df_copy, ratio)\n",
        "\n",
        "        #  Save poisoned dataset\n\n",
        "        output_file = f'{DATA_DIR}HamptonAlg_poisoned_{int(ratio*100)}.csv'\n",
        "        poisoned_df.to_csv(output_file, index=False)\n",
        "        print(f\"Saved poisoned dataset: {output_file}\")\n",
        "        files.download(output_file)  #  Uncomment if download is needed\n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e7J5lA5zFeZR",
        "outputId": "ebc0acbe-b316-4e59-9a2a-6bd1eee57cd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable Names in HamptonAlg_train.csv:\n",
            "['actionid', 'lesson', 'student', 'assessment', 'cell.context', 'UNKNOWN', 'action', 'answer', 'message', 'message.type', 'production', 'X.1', 'time', 'numstep', 'helpintermedtime', 'knowledge']\n",
            "\n",
            "Check if gaming_label exists: False\n",
            "\n",
            "Unique values in 'knowledge': [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86]\n",
            "Sample values in 'time': [174, 15, 13, 10, 6]\n",
            "Number of records: 195948\n",
            "Number of unique students: 47\n",
            "Number of unique actions: 195948\n",
            "\n",
            "Simulating DPA with 5% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 9797\n",
            "Number of final poison indices: 9797\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "knowledge distribution after 5% poisoning:\n",
            "knowledge\n",
            "22    19265\n",
            "34    13460\n",
            "3     12767\n",
            "2     10711\n",
            "20     8657\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 5% poisoning:\n",
            "gaming_label\n",
            "0    186151\n",
            "1      9797\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/HamptonAlg_poisoned_5.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24aaf5cb-4134-43c6-bc4d-f341119a4f65\", \"HamptonAlg_poisoned_5.csv\", 36379582)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating DPA with 25% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 48987\n",
            "Number of final poison indices: 48987\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "knowledge distribution after 25% poisoning:\n",
            "knowledge\n",
            "22    15435\n",
            "34    11102\n",
            "3     10228\n",
            "2      8399\n",
            "20     7304\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 25% poisoning:\n",
            "gaming_label\n",
            "0    146961\n",
            "1     48987\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/HamptonAlg_poisoned_25.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24bbb684-3bb4-4a05-8972-0bd6e9ee1807\", \"HamptonAlg_poisoned_25.csv\", 36375020)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating DPA with 50% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 97974\n",
            "Number of final poison indices: 97974\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[1, 0]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "knowledge distribution after 50% poisoning:\n",
            "knowledge\n",
            "64    10494\n",
            "22    10389\n",
            "52     8227\n",
            "34     8087\n",
            "3      6998\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 50% poisoning:\n",
            "gaming_label\n",
            "1    97974\n",
            "0    97974\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/HamptonAlg_poisoned_50.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c1e4de2-3d5f-4f8b-9645-ce48a8202259\", \"HamptonAlg_poisoned_50.csv\", 36369237)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sequence attack"
      ],
      "metadata": {
        "id": "jkjLOD5hMdOj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KiI55Ln-MfWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "#  Define global data directory for unified path management\n\n",
        "DATA_DIR = '/content/poisoned_datasets/'\n",
        "\n",
        "#  Function to load dataset\n\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load CSV file and return a DataFrame.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "#  Function to simulate Sequential Pattern Attack\n\n",
        "def simulate_sequential_pattern_attack(df, poison_ratio):\n",
        "    \"\"\"Simulate Sequential Pattern Attack on the dataset.\"\"\"\n",
        "    #  Create a deep copy to ensure data independence\n\n",
        "    df_poisoned = df.copy()\n",
        "\n",
        "    #  Initialize gaming_label column with explicit integer type\n\n",
        "    df_poisoned['gaming_label'] = 0\n",
        "    df_poisoned['gaming_label'] = df_poisoned['gaming_label'].astype('Int64')  #  Nullable integer type to handle potential NaNs\n\n",
        "\n",
        "    #  Assert key columns exist\n\n",
        "    assert 'student' in df_poisoned.columns, \"Column 'student' not found\"\n",
        "    assert 'actionid' in df_poisoned.columns, \"Column 'actionid' not found\"\n",
        "    assert 'gaming_label' in df_poisoned.columns, \"Column 'gaming_label' not initialized\"\n",
        "\n",
        "    #  Debug: Check initial unique values in gaming_label\n\n",
        "    print(f\"Initial unique values in 'gaming_label': {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Randomly select students and actions\n\n",
        "    n_poison = int(len(df) * poison_ratio // 3)  #  Adjust for 3 records per action\n\n",
        "    unique_students = df['student'].unique()\n",
        "    unique_actions = df['actionid'].unique()\n",
        "    n_select = min(int(np.sqrt(n_poison)), len(unique_students), len(unique_actions))\n",
        "\n",
        "    #  Debug: Check selection counts\n\n",
        "    print(f\"Number of records to poison: {n_poison}\")\n",
        "    print(f\"Number of unique students: {len(unique_students)}, selected: {n_select}\")\n",
        "    print(f\"Number of unique actions: {len(unique_actions)}, selected: {n_select}\")\n",
        "\n",
        "    #  Handle case where no records can be poisoned\n\n",
        "    if n_select == 0 or n_poison == 0:\n",
        "        print(\"Warning: No records selected for poisoning due to small dataset or low poison ratio.\")\n",
        "        return df_poisoned\n",
        "\n",
        "    selected_students = np.random.choice(unique_students, size=n_select, replace=False)\n",
        "    selected_actions = np.random.choice(unique_actions, size=n_select, replace=False)\n",
        "\n",
        "    #  Identify records to poison\n\n",
        "    poison_indices = df.index[\n",
        "        (df['student'].isin(selected_students)) &\n",
        "        (df['actionid'].isin(selected_actions))\n",
        "    ].tolist()\n",
        "\n",
        "    #  Debug: Check poison indices\n\n",
        "    print(f\"Number of candidate poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    poison_indices = np.random.choice(poison_indices, size=min(n_poison, len(poison_indices)), replace=False)\n",
        "\n",
        "    #  Debug: Check final poison indices\n\n",
        "    print(f\"Number of final poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    #  Process each poisoned record\n\n",
        "    new_rows = []\n",
        "    columns = df_poisoned.columns.tolist()  #  Ensure all columns are included\n\n",
        "    for idx in poison_indices:\n",
        "        original_row = df_poisoned.iloc[idx].copy()\n",
        "        #  Generate 3 submissions\n\n",
        "        for i in range(3):\n",
        "            new_row = original_row.copy()\n",
        "            new_row['gaming_label'] = 1\n",
        "            #  Answer sequence: A (0), B (1), C (2)\n\n",
        "            if i == 0:  #  First submission (wrong)\n\n",
        "                new_row['answer'] = 0  #  A (wrong)\n\n",
        "                new_row['knowledge'] = 0  #  Low knowledge\n\n",
        "            elif i == 1:  #  Second submission (wrong)\n\n",
        "                new_row['answer'] = 1  #  B (wrong)\n\n",
        "                new_row['knowledge'] = 0  #  Low knowledge\n\n",
        "            else:  #  Third submission (correct)\n\n",
        "                new_row['answer'] = 2  #  C (correct)\n\n",
        "                new_row['knowledge'] = 86  #  High knowledge\n\n",
        "            #  Set short response time (1-2 seconds)\n\n",
        "            new_row['time'] = np.random.uniform(1, 2)\n",
        "            #  Ensure new_row is a DataFrame with correct columns\n\n",
        "            new_row_df = pd.Series(new_row, index=columns).to_frame().T\n",
        "            new_rows.append(new_row_df)\n",
        "        #  Remove original poisoned index to avoid duplication\n\n",
        "        df_poisoned = df_poisoned.drop(idx)\n",
        "\n",
        "    #  Convert new_rows to DataFrame\n\n",
        "    if new_rows:\n",
        "        new_rows_df = pd.concat(new_rows, ignore_index=True)\n",
        "        #  Ensure data types match\n\n",
        "        for col in df_poisoned.columns:\n",
        "            if col in new_rows_df.columns:\n",
        "                new_rows_df[col] = new_rows_df[col].astype(df_poisoned[col].dtype)\n",
        "        df_poisoned = pd.concat([df_poisoned, new_rows_df], ignore_index=True)\n",
        "\n",
        "    #  Debug: Check unique values in gaming_label after poisoning\n\n",
        "    print(f\"Unique values in 'gaming_label' after poisoning: {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Verify changes with assertions\n\n",
        "    assert df_poisoned['gaming_label'].isin([0, 1]).all(), f\"Invalid gaming_label values: {df_poisoned['gaming_label'].unique()}\"\n",
        "    print(f\"\\nKnowledge distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['knowledge'].value_counts())\n",
        "    print(f\"Gaming_label distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['gaming_label'].value_counts())\n",
        "\n",
        "    return df_poisoned\n",
        "\n",
        "#  Main execution\n\n",
        "def main():\n",
        "    \"\"\"Main function to load data and simulate attacks.\"\"\"\n",
        "    #  Create directory for poisoned datasets\n\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "    #  Load dataset\n\n",
        "    hampton_file = '/content/HamptonAlg_train_new.csv'\n",
        "    df = load_data(hampton_file)\n",
        "\n",
        "    #  Ensure relevant columns are numeric\n\n",
        "    df['knowledge'] = pd.to_numeric(df['knowledge'], errors='coerce')\n",
        "    df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
        "    df['answer'] = pd.to_numeric(df['answer'], errors='coerce')\n",
        "\n",
        "    #  Print dataset information\n\n",
        "    print(\"Variable Names in HamptonAlg_train.csv:\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\nUnique values in 'knowledge':\", df['knowledge'].unique())\n",
        "    print(\"Sample values in 'time':\", df['time'].head().tolist())\n",
        "    print(\"Sample values in 'answer':\", df['answer'].head().tolist())\n",
        "    print(\"Number of records:\", len(df))\n",
        "    print(\"Number of unique students:\", len(df['student'].unique()))\n",
        "    print(\"Number of unique actions:\", len(df['actionid'].unique()))\n",
        "\n",
        "    #  Simulate Sequential Pattern Attack for each poison ratio\n\n",
        "    poison_ratios = [0.05, 0.25, 0.50]\n",
        "    for ratio in poison_ratios:\n",
        "        print(f\"\\nSimulating Sequential Pattern Attack with {int(ratio*100)}% Poisoning...\")\n",
        "        #  Create a fresh copy for each iteration\n\n",
        "        df_copy = df.copy()\n",
        "        poisoned_df = simulate_sequential_pattern_attack(df_copy, ratio)\n",
        "\n",
        "        #  Save poisoned dataset\n\n",
        "        output_file = f'{DATA_DIR}HamptonAlg_sequential_pattern_{int(ratio*100)}.csv'\n",
        "        poisoned_df.to_csv(output_file, index=False)\n",
        "        print(f\"Saved poisoned dataset: {output_file}\")\n",
        "        files.download(output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-plWOKeW9pzd",
        "outputId": "8a5917f0-de3d-4eb4-893a-e9c8b32a2ed3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable Names in HamptonAlg_train.csv:\n",
            "['actionid', 'lesson', 'student', 'assessment', 'cell.context', 'UNKNOWN', 'action', 'answer', 'message', 'message.type', 'production', 'X.1', 'time', 'numstep', 'helpintermedtime', 'knowledge']\n",
            "\n",
            "Unique values in 'knowledge': [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86]\n",
            "Sample values in 'time': [174, 15, 13, 10, 6]\n",
            "Sample values in 'answer': [nan, nan, nan, nan, nan]\n",
            "Number of records: 195948\n",
            "Number of unique students: 47\n",
            "Number of unique actions: 195948\n",
            "\n",
            "Simulating Sequential Pattern Attack with 5% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 3265\n",
            "Number of unique students: 47, selected: 47\n",
            "Number of unique actions: 195948, selected: 47\n",
            "Number of candidate poison indices: 47\n",
            "Number of final poison indices: 47\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "Knowledge distribution after 5% poisoning:\n",
            "knowledge\n",
            "22    20240\n",
            "34    14028\n",
            "3     13402\n",
            "2     11270\n",
            "20     8963\n",
            "      ...  \n",
            "29       44\n",
            "74       43\n",
            "50       39\n",
            "18       31\n",
            "51       28\n",
            "Name: count, Length: 87, dtype: int64\n",
            "Gaming_label distribution after 5% poisoning:\n",
            "gaming_label\n",
            "0    195901\n",
            "1       141\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/HamptonAlg_sequential_pattern_5.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e90c546-3c52-4549-8641-6897970ca93f\", \"HamptonAlg_sequential_pattern_5.csv\", 35890855)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating Sequential Pattern Attack with 25% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 16329\n",
            "Number of unique students: 47, selected: 47\n",
            "Number of unique actions: 195948, selected: 47\n",
            "Number of candidate poison indices: 47\n",
            "Number of final poison indices: 47\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "Knowledge distribution after 25% poisoning:\n",
            "knowledge\n",
            "22    20240\n",
            "34    14025\n",
            "3     13401\n",
            "2     11269\n",
            "20     8967\n",
            "      ...  \n",
            "29       44\n",
            "74       43\n",
            "50       39\n",
            "18       31\n",
            "51       28\n",
            "Name: count, Length: 87, dtype: int64\n",
            "Gaming_label distribution after 25% poisoning:\n",
            "gaming_label\n",
            "0    195901\n",
            "1       141\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/HamptonAlg_sequential_pattern_25.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c2c4388a-c340-4673-a6c8-b8fbd0b5dbe1\", \"HamptonAlg_sequential_pattern_25.csv\", 35890602)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating Sequential Pattern Attack with 50% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 32658\n",
            "Number of unique students: 47, selected: 47\n",
            "Number of unique actions: 195948, selected: 47\n",
            "Number of candidate poison indices: 47\n",
            "Number of final poison indices: 47\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "Knowledge distribution after 50% poisoning:\n",
            "knowledge\n",
            "22    20239\n",
            "34    14029\n",
            "3     13402\n",
            "2     11271\n",
            "20     8964\n",
            "      ...  \n",
            "29       44\n",
            "74       43\n",
            "50       39\n",
            "18       31\n",
            "51       28\n",
            "Name: count, Length: 87, dtype: int64\n",
            "Gaming_label distribution after 50% poisoning:\n",
            "gaming_label\n",
            "0    195901\n",
            "1       141\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/HamptonAlg_sequential_pattern_50.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_410cd49b-e63f-412d-aa7e-4000dfb4e082\", \"HamptonAlg_sequential_pattern_50.csv\", 35894415)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "#  Define global data directory for unified path management\n\n",
        "DATA_DIR = '/content/poisoned_datasets/'\n",
        "\n",
        "#  Function to load dataset\n\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load CSV file and return a DataFrame.\"\"\"\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    return df\n",
        "\n",
        "#  Function to simulate Sequential Pattern Attack\n\n",
        "def simulate_sequential_pattern_attack(df, poison_ratio):\n",
        "    \"\"\"Simulate Sequential Pattern Attack on the dataset.\"\"\"\n",
        "    #  Create a deep copy to ensure data independence\n\n",
        "    df_poisoned = df.copy()\n",
        "\n",
        "    #  Initialize gaming_label column with explicit integer type\n\n",
        "    df_poisoned['gaming_label'] = 0\n",
        "    df_poisoned['gaming_label'] = df_poisoned['gaming_label'].astype('Int64')  #  Nullable integer type\n\n",
        "\n",
        "    #  Assert key columns exist\n\n",
        "    assert 'studentId' in df_poisoned.columns, \"Column 'studentId' not found\"\n",
        "    assert 'problemId' in df_poisoned.columns, \"Column 'problemId' not found\"\n",
        "    assert 'correct' in df_poisoned.columns, \"Column 'correct' not found\"\n",
        "    assert 'timeTaken' in df_poisoned.columns, \"Column 'timeTaken' not found\"\n",
        "    assert 'gaming_label' in df_poisoned.columns, \"Column 'gaming_label' not initialized\"\n",
        "\n",
        "    #  Debug: Check initial unique values in gaming_label\n\n",
        "    print(f\"Initial unique values in 'gaming_label': {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Randomly select students and problems\n\n",
        "    n_poison = int(len(df) * poison_ratio)  #  Total number of records to poison\n\n",
        "    unique_students = df['studentId'].unique()\n",
        "    unique_problems = df['problemId'].unique()\n",
        "    n_select = min(int(0.1 * len(unique_students)), 100, len(unique_students), len(unique_problems))  #  Limit to 10% or 100\n\n",
        "\n",
        "    #  Debug: Check selection counts\n\n",
        "    print(f\"Number of records to poison: {n_poison}\")\n",
        "    print(f\"Number of unique students: {len(unique_students)}, selected: {n_select}\")\n",
        "    print(f\"Number of unique problems: {len(unique_problems)}, selected: {n_select}\")\n",
        "\n",
        "    #  Handle case where no records can be poisoned\n\n",
        "    if n_select == 0 or n_poison == 0:\n",
        "        print(\"Warning: No records selected for poisoning due to small dataset or low poison ratio.\")\n",
        "        return df_poisoned\n",
        "\n",
        "    selected_students = np.random.choice(unique_students, size=n_select, replace=False)\n",
        "    selected_problems = np.random.choice(unique_problems, size=n_select, replace=False)\n",
        "\n",
        "    #  Identify records to poison\n\n",
        "    mask = (df['studentId'].isin(selected_students)) & (df['problemId'].isin(selected_problems))\n",
        "    poison_indices = df.index[mask].tolist()\n",
        "\n",
        "    #  Debug: Check poison indices\n\n",
        "    print(f\"Number of candidate poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    poison_indices = np.random.choice(poison_indices, size=min(n_poison, len(poison_indices)), replace=False)\n",
        "\n",
        "    #  Debug: Check final poison indices\n\n",
        "    print(f\"Number of final poison indices: {len(poison_indices)}\")\n",
        "\n",
        "    #  Generate new rows in bulk\n\n",
        "    new_rows = []\n",
        "    columns = df_poisoned.columns.tolist()  #  Ensure all columns are included\n\n",
        "    if len(poison_indices) > 0:\n",
        "        n_new_rows = len(poison_indices) * 2  #  2 new rows per poisoned record\n\n",
        "        for idx in poison_indices:\n",
        "            base_row = df_poisoned.loc[idx].copy()\n",
        "            #  Generate two new submissions (A and B, both wrong)\n\n",
        "            for i in range(2):\n",
        "                new_row = base_row.copy()\n",
        "                new_row['gaming_label'] = 1\n",
        "                new_row['correct'] = 0  #  Wrong answer (A or B)\n\n",
        "                new_row['timeTaken'] = np.random.uniform(1, 2)\n",
        "                #  Ensure new_row is a DataFrame with correct columns\n\n",
        "                new_row_df = pd.Series(new_row, index=columns).to_frame().T\n",
        "                new_rows.append(new_row_df)\n",
        "            #  Update original row (third submission, correct)\n\n",
        "            df_poisoned.loc[idx, 'correct'] = 1\n",
        "            df_poisoned.loc[idx, 'timeTaken'] = np.random.uniform(1, 2)\n",
        "            df_poisoned.loc[idx, 'gaming_label'] = 1\n",
        "\n",
        "        #  Convert new_rows to DataFrame\n\n",
        "        if new_rows:\n",
        "            new_rows_df = pd.concat(new_rows, ignore_index=True)\n",
        "            #  Ensure data types match\n\n",
        "            for col in df_poisoned.columns:\n",
        "                if col in new_rows_df.columns:\n",
        "                    new_rows_df[col] = new_rows_df[col].astype(df_poisoned[col].dtype)\n",
        "            df_poisoned = pd.concat([df_poisoned, new_rows_df], ignore_index=True)\n",
        "\n",
        "    #  Debug: Check unique values in gaming_label after poisoning\n\n",
        "    print(f\"Unique values in 'gaming_label' after poisoning: {df_poisoned['gaming_label'].unique()}\")\n",
        "\n",
        "    #  Verify changes with assertions\n\n",
        "    assert df_poisoned['gaming_label'].isin([0, 1]).all(), f\"Invalid gaming_label values: {df_poisoned['gaming_label'].unique()}\"\n",
        "    print(f\"\\nCorrect distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['correct'].value_counts().head())\n",
        "    print(f\"Gaming_label distribution after {int(poison_ratio*100)}% poisoning:\")\n",
        "    print(df_poisoned['gaming_label'].value_counts().head())\n",
        "\n",
        "    return df_poisoned\n",
        "\n",
        "#  Main execution\n\n",
        "def main():\n",
        "    \"\"\"Main function to load data and simulate attacks.\"\"\"\n",
        "    #  Create directory for poisoned datasets\n\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "    #  Load dataset\n\n",
        "    assistment_file = 'Assistment_challenge_train_new.csv'\n",
        "    df = load_data(assistment_file)\n",
        "\n",
        "    #  Ensure relevant columns are numeric\n\n",
        "    for col in ['correct', 'timeTaken']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    #  Print basic info\n\n",
        "    print(f\"Loaded dataset with {len(df)} records\")\n",
        "    print(\"Variable Names in Assistment_challenge_train.csv:\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\nUnique values in 'correct':\", df['correct'].unique())\n",
        "    print(\"Sample values in 'timeTaken':\", df['timeTaken'].head().tolist())\n",
        "    print(\"Number of unique students:\", len(df['studentId'].unique()))\n",
        "    print(\"Number of unique problems:\", len(df['problemId'].unique()))\n",
        "\n",
        "    #  Simulate Sequential Pattern Attack for each poison ratio\n\n",
        "    poison_ratios = [0.05, 0.25, 0.50]\n",
        "    for ratio in poison_ratios:\n",
        "        print(f\"\\nSimulating Sequential Pattern Attack with {int(ratio*100)}% Poisoning...\")\n",
        "        #  Create a fresh copy for each iteration\n\n",
        "        df_copy = df.copy()\n",
        "        poisoned_df = simulate_sequential_pattern_attack(df_copy, ratio)\n",
        "\n",
        "        #  Save poisoned dataset\n\n",
        "        output_file = f'{DATA_DIR}Assistment_sequential_pattern_{int(ratio*100)}.csv'\n",
        "        poisoned_df.to_csv(output_file, index=False, chunksize=10000)\n",
        "        print(f\"Saved poisoned dataset: {output_file}\")\n",
        "        files.download(output_file)  #  Uncomment if download is needed\n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KBL5UxQVAUVj",
        "outputId": "dfac04a9-3ba7-4092-e1ab-465144ea7fce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 140090 records\n",
            "Variable Names in Assistment_challenge_train.csv:\n",
            "['studentId', 'MiddleSchoolId', 'InferredGender', 'SY ASSISTments Usage', 'AveKnow', 'AveCarelessness', 'AveCorrect', 'NumActions', 'AveResBored', 'AveResEngcon', 'AveResConf', 'AveResFrust', 'AveResOfftask', 'AveResGaming', 'action_num', 'skill', 'problemId', 'problemType', 'assignmentId', 'assistmentId', 'startTime', 'endTime', 'timeTaken', 'correct', 'original', 'hint', 'hintCount', 'hintTotal', 'scaffold', 'bottomHint', 'attemptCount', 'frIsHelpRequest', 'frPast5HelpRequest', 'frPast8HelpRequest', 'stlHintUsed', 'past8BottomOut', 'totalFrPercentPastWrong', 'totalFrPastWrongCount', 'frPast5WrongCount', 'frPast8WrongCount', 'totalFrTimeOnSkill', 'timeSinceSkill', 'frWorkingInSchool', 'totalFrAttempted', 'totalFrSkillOpportunities', 'responseIsFillIn', 'responseIsChosen', 'endsWithScaffolding', 'endsWithAutoScaffolding', 'frTimeTakenOnScaffolding', 'frTotalSkillOpportunitiesScaffolding', 'totalFrSkillOpportunitiesByScaffolding', 'frIsHelpRequestScaffolding', 'timeGreater5Secprev2wrong', 'sumRight', 'helpAccessUnder2Sec', 'timeGreater10SecAndNextActionRight', 'consecutiveErrorsInRow', 'sumTime3SDWhen3RowRight', 'sumTimePerSkill', 'totalTimeByPercentCorrectForskill', 'Prev5count', 'timeOver80', 'manywrong', 'confidence(BORED)', 'confidence(CONCENTRATING)', 'confidence(CONFUSED)', 'confidence(FRUSTRATED)', 'confidence(OFF TASK)', 'confidence(GAMING)', 'RES_BORED', 'RES_CONCENTRATING', 'RES_CONFUSED', 'RES_FRUSTRATED', 'RES_OFFTASK', 'RES_GAMING', 'Ln-1', 'Ln', 'MCAS', 'Enrolled', 'Selective', 'isSTEM', 'knowledge']\n",
            "\n",
            "Unique values in 'correct': [0 1]\n",
            "Sample values in 'timeTaken': [49.0, 3.999999762, 83.00000048, 5.0, 12.00000024]\n",
            "Number of unique students: 1352\n",
            "Number of unique problems: 1452\n",
            "\n",
            "Simulating Sequential Pattern Attack with 5% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 7004\n",
            "Number of unique students: 1352, selected: 100\n",
            "Number of unique problems: 1452, selected: 100\n",
            "Number of candidate poison indices: 591\n",
            "Number of final poison indices: 591\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "Correct distribution after 5% poisoning:\n",
            "correct\n",
            "0    91232\n",
            "1    50040\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 5% poisoning:\n",
            "gaming_label\n",
            "0    139499\n",
            "1      1773\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/Assistment_sequential_pattern_5.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60613b4b-3307-4f48-a652-b89684afb6b8\", \"Assistment_sequential_pattern_5.csv\", 81158324)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating Sequential Pattern Attack with 25% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 35022\n",
            "Number of unique students: 1352, selected: 100\n",
            "Number of unique problems: 1452, selected: 100\n",
            "Number of candidate poison indices: 653\n",
            "Number of final poison indices: 653\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "Correct distribution after 25% poisoning:\n",
            "correct\n",
            "0    91329\n",
            "1    50067\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 25% poisoning:\n",
            "gaming_label\n",
            "0    139437\n",
            "1      1959\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/Assistment_sequential_pattern_25.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7dcb6b95-0a2f-499f-bf9e-7a8aee1df792\", \"Assistment_sequential_pattern_25.csv\", 81226029)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating Sequential Pattern Attack with 50% Poisoning...\n",
            "Initial unique values in 'gaming_label': <IntegerArray>\n",
            "[0]\n",
            "Length: 1, dtype: Int64\n",
            "Number of records to poison: 70045\n",
            "Number of unique students: 1352, selected: 100\n",
            "Number of unique problems: 1452, selected: 100\n",
            "Number of candidate poison indices: 935\n",
            "Number of final poison indices: 935\n",
            "Unique values in 'gaming_label' after poisoning: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64\n",
            "\n",
            "Correct distribution after 50% poisoning:\n",
            "correct\n",
            "0    91671\n",
            "1    50289\n",
            "Name: count, dtype: int64\n",
            "Gaming_label distribution after 50% poisoning:\n",
            "gaming_label\n",
            "0    139155\n",
            "1      2805\n",
            "Name: count, dtype: Int64\n",
            "Saved poisoned dataset: /content/poisoned_datasets/Assistment_sequential_pattern_50.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_645b7759-979a-4857-b6ce-23add8e95c34\", \"Assistment_sequential_pattern_50.csv\", 81541825)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}