{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyBKT.models import Model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess(dataset_name):\n",
    "    if dataset_name==\"HamptonAlg\":\n",
    "        df = pd.read_csv(\"data/raw_data/HamptonAlg_processed.csv\")\n",
    "        print(f\"Number of rows before processing: {len(df)}\")\n",
    "        df = df[df['production'] != 'BLANK']  # Remove 'BLANK'\n",
    "        print(f\"Number of rows after : {len(df)}\")\n",
    "        production_mapping = {prod: idx for idx, prod in enumerate(df['production'].unique())}\n",
    "        #print(df['production'].unique())\n",
    "        df['knowledge'] = df['production'].map(production_mapping)\n",
    "        pd.Series(production_mapping).to_csv('data/raw_data/HamptonAlg_production_mapping.csv')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    elif dataset_name==\"Assistment_challenge\":\n",
    "        df = pd.read_csv(\"data/raw_data/assistant_competition.csv\")\n",
    "        print(f\"Number of rows before processing: {len(df)}\")\n",
    "       \n",
    "        print(f\"Number of rows after : {len(df)}\")\n",
    "        skill_mapping = {prod: idx for idx, prod in enumerate(df['skill'].unique())}\n",
    "        #print(df['skill'].unique())\n",
    "        df['knowledge'] = df['skill'].map(skill_mapping)\n",
    "        \n",
    "       # df['skill'] = df['skill'].map(skill_mapping)\n",
    "        pd.Series(skill_mapping).to_csv('data/raw_data/assistant_competition_skill_mapping.csv')\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"no such dataset!\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a208ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset_name,knowledge_column_name, student_column_name):\n",
    "    \n",
    "    test_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "    \n",
    "    df = read_and_preprocess(dataset_name)\n",
    "    \n",
    "    skill_count = 1\n",
    "    \n",
    "    for skill, skill_group in df.groupby(knowledge_column_name):\n",
    "        print(f\"Skill: {skill} — Total records: {len(skill_group)}\")\n",
    "\n",
    "        # Get all unique students for this skill\n",
    "        unique_students = skill_group[student_column_name].unique()\n",
    "        \n",
    "        if len(unique_students)<5:\n",
    "            continue\n",
    "\n",
    "        # Sample 20% of the students\n",
    "        n_sample = max(1, int(len(unique_students) * 0.2))  # ensure at least 1\n",
    "        sampled_students = pd.Series(unique_students).sample(n=n_sample, random_state=42)\n",
    "\n",
    "        # Split the skill_group based on whether student is in test or train\n",
    "        test_part = skill_group[skill_group[student_column_name].isin(sampled_students)]\n",
    "        train_part = skill_group[~skill_group[student_column_name].isin(sampled_students)]\n",
    "\n",
    "        # Append to overall DataFrames\n",
    "        test_df = pd.concat([test_df, test_part])\n",
    "        train_df = pd.concat([train_df, train_part])\n",
    "\n",
    "            \n",
    "\n",
    "    # Step 3: Reset index (optional)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f\"Train set size: {len(train_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Step 5: Compare skills in train and test\n",
    "    train_skills = set(train_df[knowledge_column_name].unique())\n",
    "    test_skills = set(test_df[knowledge_column_name].unique())\n",
    "\n",
    "    missing_skills = test_skills - train_skills\n",
    "\n",
    "    if not missing_skills:\n",
    "        print(\"✅ All skills in the test set are also present in the training set.\")\n",
    "        train_df.to_csv(dataset_name+ \"_train.csv\", index=False)\n",
    "        test_df.to_csv(dataset_name +\"_test.csv\", index=False)\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ The following skills are in the test set but missing in the training set:\")\n",
    "        print(missing_skills)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split(\"HamptonAlg\",\"knowledge\",\"student\")\n",
    "train_test_split(\"Assistment_challenge\",\"knowledge\",\"studentId\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
